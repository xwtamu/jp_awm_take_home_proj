{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "311cd9c3-6cdb-4898-852e-a201bea86973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\xiaow\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## import libraries\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import re\n",
    "from scipy.stats import zscore, shapiro\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5cb1c0-3ab4-4cf8-9409-fb34f1ecaba0",
   "metadata": {},
   "source": [
    "## Step 1. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb8cd8-1a08-45c8-aae2-daae150ba1d1",
   "metadata": {},
   "source": [
    "### Step 1.1. Load the training dataset and perform an initial data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c186eb-55e4-4dd0-a624-098c31bc94be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Training data shape: (199121, 24)\n",
      "dependent variable is: bad_flag\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>desc</th>\n",
       "      <th>purpose</th>\n",
       "      <th>...</th>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>application_approved_flag</th>\n",
       "      <th>internal_score</th>\n",
       "      <th>bad_flag</th>\n",
       "      <th>train_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000001</td>\n",
       "      <td>11983056.0</td>\n",
       "      <td>7550</td>\n",
       "      <td>36 months</td>\n",
       "      <td>16.24%</td>\n",
       "      <td>3 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>72%</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3828.953801</td>\n",
       "      <td>5759.0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000002</td>\n",
       "      <td>12002921.0</td>\n",
       "      <td>27050</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.99%</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>OWN</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Borrower added on 12/31/13 &gt; Combining high ...</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>61.20%</td>\n",
       "      <td>35700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34359.940730</td>\n",
       "      <td>114834.0</td>\n",
       "      <td>1</td>\n",
       "      <td>353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000003</td>\n",
       "      <td>11983096.0</td>\n",
       "      <td>12000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.99%</td>\n",
       "      <td>4 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>Borrower added on 12/31/13 &gt; I would like to...</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24%</td>\n",
       "      <td>18100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16416.617760</td>\n",
       "      <td>7137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000004</td>\n",
       "      <td>12003142.0</td>\n",
       "      <td>28000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.62%</td>\n",
       "      <td>5 years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.60%</td>\n",
       "      <td>42200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38014.149760</td>\n",
       "      <td>799592.0</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000005</td>\n",
       "      <td>11993233.0</td>\n",
       "      <td>12000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.53%</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>68.80%</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6471.462236</td>\n",
       "      <td>13605.0</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   member_id  loan_amnt        term int_rate emp_length  \\\n",
       "0  10000001  11983056.0       7550   36 months   16.24%    3 years   \n",
       "1  10000002  12002921.0      27050   36 months   10.99%  10+ years   \n",
       "2  10000003  11983096.0      12000   36 months   10.99%    4 years   \n",
       "3  10000004  12003142.0      28000   36 months    7.62%    5 years   \n",
       "4  10000005  11993233.0      12000   36 months   13.53%  10+ years   \n",
       "\n",
       "  home_ownership  annual_inc  \\\n",
       "0           RENT     28000.0   \n",
       "1            OWN     55000.0   \n",
       "2           RENT     60000.0   \n",
       "3       MORTGAGE    325000.0   \n",
       "4           RENT     40000.0   \n",
       "\n",
       "                                                desc             purpose  ...  \\\n",
       "0                                                NaN  debt_consolidation  ...   \n",
       "1    Borrower added on 12/31/13 > Combining high ...  debt_consolidation  ...   \n",
       "2    Borrower added on 12/31/13 > I would like to...  debt_consolidation  ...   \n",
       "3                                                NaN  debt_consolidation  ...   \n",
       "4                                                NaN  debt_consolidation  ...   \n",
       "\n",
       "   mths_since_recent_inq  revol_util  total_bc_limit  \\\n",
       "0                   17.0         72%          4000.0   \n",
       "1                    8.0      61.20%         35700.0   \n",
       "2                    3.0         24%         18100.0   \n",
       "3                    3.0      54.60%         42200.0   \n",
       "4                   17.0      68.80%          7000.0   \n",
       "\n",
       "   mths_since_last_major_derog  tot_hi_cred_lim tot_cur_bal  \\\n",
       "0                          NaN      3828.953801      5759.0   \n",
       "1                          NaN     34359.940730    114834.0   \n",
       "2                          NaN     16416.617760      7137.0   \n",
       "3                          NaN     38014.149760    799592.0   \n",
       "4                         53.0      6471.462236     13605.0   \n",
       "\n",
       "   application_approved_flag  internal_score  bad_flag  train_indicator  \n",
       "0                          1              99       0.0              1.0  \n",
       "1                          1             353       0.0              1.0  \n",
       "2                          1             157       0.0              1.0  \n",
       "3                          1             365       0.0              1.0  \n",
       "4                          1             157       0.0              1.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading training data...\")\n",
    "train_df = pd.read_csv('C:/Users/xiaow/work/jp_awm/interview/Take Home Project/training_loan_data.csv', header=1)\n",
    "ind_col = 'train_indicator'\n",
    "train_df[ind_col] = 1.0\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "y_col = 'bad_flag'\n",
    "print(\"dependent variable is: \" + y_col)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ccfd6ad-9d0e-414a-89ee-b4f56a3b8259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading testing data...\n",
      "Testing data shape: (102505, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>desc</th>\n",
       "      <th>purpose</th>\n",
       "      <th>...</th>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>application_approved_flag</th>\n",
       "      <th>internal_score</th>\n",
       "      <th>bad_flag</th>\n",
       "      <th>train_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000001</td>\n",
       "      <td>22419852</td>\n",
       "      <td>10000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>22.15%</td>\n",
       "      <td>8 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>73.10%</td>\n",
       "      <td>16200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14877.170280</td>\n",
       "      <td>36809</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000002</td>\n",
       "      <td>22349118</td>\n",
       "      <td>1400</td>\n",
       "      <td>36 months</td>\n",
       "      <td>18.24%</td>\n",
       "      <td>6 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>41000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.50%</td>\n",
       "      <td>4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4097.304770</td>\n",
       "      <td>19536</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000003</td>\n",
       "      <td>22398818</td>\n",
       "      <td>7000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>12.49%</td>\n",
       "      <td>3 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>68900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>48.10%</td>\n",
       "      <td>11900</td>\n",
       "      <td>80.0</td>\n",
       "      <td>12688.495160</td>\n",
       "      <td>241465</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000004</td>\n",
       "      <td>22419015</td>\n",
       "      <td>18000</td>\n",
       "      <td>60 months</td>\n",
       "      <td>16.29%</td>\n",
       "      <td>9 years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>41000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.10%</td>\n",
       "      <td>7600</td>\n",
       "      <td>73.0</td>\n",
       "      <td>7908.799817</td>\n",
       "      <td>179757</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000005</td>\n",
       "      <td>22388614</td>\n",
       "      <td>12000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>12.99%</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.90%</td>\n",
       "      <td>21000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19378.561060</td>\n",
       "      <td>31953</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  member_id  loan_amnt        term int_rate emp_length  \\\n",
       "0  20000001   22419852      10000   36 months   22.15%    8 years   \n",
       "1  20000002   22349118       1400   36 months   18.24%    6 years   \n",
       "2  20000003   22398818       7000   36 months   12.49%    3 years   \n",
       "3  20000004   22419015      18000   60 months   16.29%    9 years   \n",
       "4  20000005   22388614      12000   36 months   12.99%  10+ years   \n",
       "\n",
       "  home_ownership  annual_inc desc             purpose  ...  \\\n",
       "0           RENT     37000.0  NaN  debt_consolidation  ...   \n",
       "1           RENT     41000.0  NaN               other  ...   \n",
       "2           RENT     68900.0  NaN  debt_consolidation  ...   \n",
       "3       MORTGAGE     41000.0  NaN  debt_consolidation  ...   \n",
       "4       MORTGAGE     64000.0  NaN    home_improvement  ...   \n",
       "\n",
       "   mths_since_recent_inq  revol_util  total_bc_limit  \\\n",
       "0                    3.0      73.10%           16200   \n",
       "1                    9.0      11.50%            4000   \n",
       "2                   11.0      48.10%           11900   \n",
       "3                    0.0      38.10%            7600   \n",
       "4                    NaN      57.90%           21000   \n",
       "\n",
       "   mths_since_last_major_derog  tot_hi_cred_lim tot_cur_bal  \\\n",
       "0                          NaN     14877.170280       36809   \n",
       "1                          NaN      4097.304770       19536   \n",
       "2                         80.0     12688.495160      241465   \n",
       "3                         73.0      7908.799817      179757   \n",
       "4                          NaN     19378.561060       31953   \n",
       "\n",
       "   application_approved_flag  internal_score  bad_flag  train_indicator  \n",
       "0                          1             131       NaN              0.0  \n",
       "1                          1              19       NaN              0.0  \n",
       "2                          1              92       NaN              0.0  \n",
       "3                          1             235       NaN              0.0  \n",
       "4                          1             157       NaN              0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading testing data...\")\n",
    "test_df = pd.read_csv('C:/Users/xiaow/work/jp_awm/interview/Take Home Project/testing_loan_data.csv', header=0)\n",
    "test_df[ind_col] = 0.0\n",
    "print(f\"Testing data shape: {test_df.shape}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e98474c-9a48-4fc7-bc8e-4953ce3fa010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Train Data Types and Missing Values ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199121 entries, 0 to 199120\n",
      "Data columns (total 24 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   id                           199121 non-null  int64  \n",
      " 1   member_id                    189457 non-null  float64\n",
      " 2   loan_amnt                    199121 non-null  int64  \n",
      " 3   term                         189457 non-null  object \n",
      " 4   int_rate                     189457 non-null  object \n",
      " 5   emp_length                   181531 non-null  object \n",
      " 6   home_ownership               189457 non-null  object \n",
      " 7   annual_inc                   189457 non-null  float64\n",
      " 8   desc                         82004 non-null   object \n",
      " 9   purpose                      189457 non-null  object \n",
      " 10  percent_bc_gt_75             180419 non-null  float64\n",
      " 11  bc_util                      180333 non-null  float64\n",
      " 12  dti                          189457 non-null  float64\n",
      " 13  inq_last_6mths               189457 non-null  float64\n",
      " 14  mths_since_recent_inq        161472 non-null  float64\n",
      " 15  revol_util                   189330 non-null  object \n",
      " 16  total_bc_limit               181962 non-null  float64\n",
      " 17  mths_since_last_major_derog  32749 non-null   float64\n",
      " 18  tot_hi_cred_lim              181962 non-null  float64\n",
      " 19  tot_cur_bal                  161716 non-null  float64\n",
      " 20  application_approved_flag    199121 non-null  int64  \n",
      " 21  internal_score               199121 non-null  int64  \n",
      " 22  bad_flag                     189457 non-null  float64\n",
      " 23  train_indicator              199121 non-null  float64\n",
      "dtypes: float64(13), int64(4), object(7)\n",
      "memory usage: 36.5+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Train Data Types and Missing Values ===\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "061ba5b5-9f70-4fdb-8c1b-f08ff279c22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Data Types and Missing Values ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102505 entries, 0 to 102504\n",
      "Data columns (total 24 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   id                           102505 non-null  int64  \n",
      " 1   member_id                    102505 non-null  int64  \n",
      " 2   loan_amnt                    102505 non-null  int64  \n",
      " 3   term                         102505 non-null  object \n",
      " 4   int_rate                     102505 non-null  object \n",
      " 5   emp_length                   97184 non-null   object \n",
      " 6   home_ownership               102505 non-null  object \n",
      " 7   annual_inc                   102505 non-null  float64\n",
      " 8   desc                         15194 non-null   object \n",
      " 9   purpose                      102505 non-null  object \n",
      " 10  percent_bc_gt_75             101459 non-null  float64\n",
      " 11  bc_util                      101463 non-null  float64\n",
      " 12  dti                          102505 non-null  float64\n",
      " 13  inq_last_6mths               102505 non-null  int64  \n",
      " 14  mths_since_recent_inq        93677 non-null   float64\n",
      " 15  revol_util                   102457 non-null  object \n",
      " 16  total_bc_limit               102505 non-null  int64  \n",
      " 17  mths_since_last_major_derog  29146 non-null   float64\n",
      " 18  tot_hi_cred_lim              102505 non-null  float64\n",
      " 19  tot_cur_bal                  102505 non-null  int64  \n",
      " 20  application_approved_flag    102505 non-null  int64  \n",
      " 21  internal_score               102505 non-null  int64  \n",
      " 22  bad_flag                     0 non-null       float64\n",
      " 23  train_indicator              102505 non-null  float64\n",
      "dtypes: float64(9), int64(8), object(7)\n",
      "memory usage: 18.8+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Test Data Types and Missing Values ===\")\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3300183-afe7-4440-a7e9-b201475df1b8",
   "metadata": {},
   "source": [
    "### Step 1.2. Data Cleaning and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b173bd-947f-4136-aa2b-cfc515490435",
   "metadata": {},
   "source": [
    "#### Step 1.2.1. Remove rows in training data with missing dependent (i.e., 5% rows with missing y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "406341a3-5778-43fb-ae76-637cb9457fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the logic is that the rows in the training dataset with missing dependent variable will\n",
    "## not contribute to the machine learning model training process and thus have to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab6cb62b-5a99-44df-80d1-62d1bee2af07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataframe with non-missing dependent variable\n",
      "(189457, 24)\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.loc[train_df['bad_flag'].notnull(), :].copy()\n",
    "print('shape of dataframe with non-missing dependent variable')\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f68f8c-69f3-413f-aca2-a54547276657",
   "metadata": {},
   "source": [
    "#### Step 1.2.2. Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8491f21-bd73-44af-a536-ea7b2b382e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## logic is that add the duplicated rows into the model will not boost the training or prediction\n",
    "## performance. It will overweight certain observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c01d7eb-1999-4bdc-80eb-9afb5e6b5a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before drop duplicates\n",
      "(189457, 24)\n",
      "shape after drop duplicates\n",
      "(188123, 24)\n"
     ]
    }
   ],
   "source": [
    "print('shape before drop duplicates')\n",
    "print(train_df.shape)\n",
    "train_df = train_df.drop_duplicates()\n",
    "print('shape after drop duplicates')\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f41f3e-4b5c-4392-8b90-7379c028f9f5",
   "metadata": {},
   "source": [
    "#### Step 1.2.3. Combine train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99ff7aec-e49f-4636-af92-5d125451ab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(290628, 24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([train_df, test_df], axis=0)\n",
    "print(len(combined_df) - len(train_df) - len(test_df))\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61255fce-2a94-4974-93a8-fa3c00bcece0",
   "metadata": {},
   "source": [
    "#### Step 1.2.3. Drop IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbb6dcee-06af-48a1-b16e-7f37e798a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ID columns don’t carry useful patterns for prediction and can hurt model performance,\n",
    "## e.g., overfitting or inflated feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8accc56-4241-49c2-9df6-bb789af1c57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290628, 24)\n",
      "(188123, 24)\n",
      "member_id\n",
      "id\n",
      "(290628, 22)\n",
      "(188123, 24)\n"
     ]
    }
   ],
   "source": [
    "print(combined_df.shape)\n",
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "for x in ['member_id', 'id']:\n",
    "    print(x)\n",
    "    assert train_df[x].nunique() == len(train_df)\n",
    "    assert test_df[x].nunique() == len(test_df)\n",
    "    del combined_df[x]\n",
    "print(combined_df.shape)\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf42033a-adc6-4e8e-adab-66f77fcac40f",
   "metadata": {},
   "source": [
    "#### Step 1.2.4. Drop columns that contains single values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a449dc2a-7f70-4848-aabc-57a9de416d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this kind of columns does not provide any useful information, and thus need to be removed, i.e., application_approved_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67374e40-9a78-4c34-8b5c-5c385b8d439b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188123, 22)\n",
      "{'application_approved_flag'}\n",
      "(290628, 22)\n",
      "(290628, 21)\n"
     ]
    }
   ],
   "source": [
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "problem_cols = set([x for x in train_df.columns if train_df[x].nunique() == 1]).difference(set([ind_col]))\n",
    "print(problem_cols)\n",
    "print(combined_df.shape)\n",
    "for x in problem_cols:\n",
    "    del combined_df[x]\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5840a61-8b69-4e10-afe1-aa229fc1fec8",
   "metadata": {},
   "source": [
    "#### Step 1.2.5. Drop columns with missing rate too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8e87ff7-9964-481e-babd-2fdfa020506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## idea is that if the columns has too many missings, and it does not have\n",
    "## high correlation with dependent variable, then it does not contribute to\n",
    "## the model training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5db22f56-537f-4c44-898c-23d6ebe1026e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188123, 21)\n",
      "loan_amnt 0.0\n",
      "term 0.0\n",
      "int_rate 0.0\n",
      "emp_length 4.1871541491471005\n",
      "home_ownership 0.0\n",
      "annual_inc 0.0\n",
      "desc 56.69801140743024\n",
      "purpose 0.0\n",
      "percent_bc_gt_75 4.798456329103831\n",
      "bc_util 4.843107966596323\n",
      "dti 0.0\n",
      "inq_last_6mths 0.0\n",
      "mths_since_recent_inq 14.809459768343052\n",
      "revol_util 0.06644588912573157\n",
      "total_bc_limit 3.984095511978865\n",
      "mths_since_last_major_derog 82.72566352864881\n",
      "tot_hi_cred_lim 3.984095511978865\n",
      "tot_cur_bal 14.746203281895356\n",
      "internal_score 0.0\n",
      "bad_flag 0.0\n",
      "train_indicator 0.0\n"
     ]
    }
   ],
   "source": [
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "for x in train_df.columns:\n",
    "    missing_rate = 100.0 * train_df[x].isnull().sum() / len(train_df)\n",
    "    print(x + ' ' + str(missing_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90b2c27b-68ce-4702-9875-f11fe727c2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290628, 21)\n",
      "(290628, 20)\n"
     ]
    }
   ],
   "source": [
    "print(combined_df.shape)\n",
    "del combined_df['mths_since_last_major_derog']\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5582a53c-99bc-4f01-814b-ed39b7bd44e1",
   "metadata": {},
   "source": [
    "#### Step 1.2.6. Convert int columns to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d223acd6-4af4-470e-b274-82b919572a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## idea is that those int columns, loan_amnt and internal_score, are numerically comparable, \n",
    "## e.g., loan_amnt = 10 vs. loan_amnt = 20 means the 2nd one has twice the amount, thus make sense to convert to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c0d06e0-8202-4c3e-b87a-b515745a0045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188123, 20)\n",
      "(290628, 20)\n",
      "loan_amnt\n",
      "internal_score\n",
      "(290628, 20)\n"
     ]
    }
   ],
   "source": [
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "print(combined_df.shape)\n",
    "int_cols = train_df.select_dtypes(include='int64').columns\n",
    "for x in int_cols:\n",
    "    print(x)\n",
    "    combined_df[x] = combined_df[x].astype(float)\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dac5ef-1be6-44ad-8827-0520ba8aca92",
   "metadata": {},
   "source": [
    "#### Step 1.2.7 Convert some objective columns to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d05b90d-eb42-490a-a734-032c1aa36dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## idea is that there are some columns ending with %, which should be numerical values, convert them from string to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2abd0523-6918-44c9-acfc-c8e7a420d719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188123, 20)\n",
      "(290628, 20)\n",
      "Converted column 'int_rate' from percentage string to float.\n",
      "Converted column 'revol_util' from percentage string to float.\n",
      "(188123, 20)\n",
      "(290628, 20)\n"
     ]
    }
   ],
   "source": [
    "def convert_specified_percent_columns(df, percent_cols, divide_by_100=True):\n",
    "    \"\"\"\n",
    "    Convert specified columns with values ending in '%' to floats.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        Input dataset.\n",
    "    percent_cols : list\n",
    "        List of column names to convert.\n",
    "    divide_by_100 : bool, default=True\n",
    "        If True, converts percentages to fractions (e.g., '50%' -> 0.5).\n",
    "        If False, keeps numeric values as is (e.g., '50%' -> 50.0).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    df_copy : pandas DataFrame\n",
    "        DataFrame with specified percentage columns converted to float.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    for col in percent_cols:\n",
    "        if col in df_copy.columns:\n",
    "            df_copy[col] = df_copy[col].astype(str).str.rstrip('%').astype(float)\n",
    "            if divide_by_100:\n",
    "                df_copy[col] = df_copy[col] / 100.0\n",
    "            print(f\"Converted column '{col}' from percentage string to float.\")\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in DataFrame.\")\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "print(combined_df.shape)\n",
    "combined_df = convert_specified_percent_columns(combined_df, percent_cols=['int_rate', 'revol_util'], divide_by_100=True)\n",
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e69268-4c39-4586-8440-0c1ecb86975a",
   "metadata": {},
   "source": [
    "#### Step 1.2.8. Deal with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dda432b-e8d4-4fa8-b056-74377df015ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## idea is that desc has lots of missing values but it contains useful information and thus should not be removed, first ignore \n",
    "## desc, and for the rest of the dependent variables, use iterative imputer to impute missing values in numerical columns.\n",
    "## for category columns, simply using mode to impute (do not use dependent!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45546a2d-ffd2-42e3-a231-2b6ce7d4704e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188123, 20)\n",
      "(188123, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Missing_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>desc</th>\n",
       "      <td>106662</td>\n",
       "      <td>56.698011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <td>27860</td>\n",
       "      <td>14.809460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <td>27741</td>\n",
       "      <td>14.746203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc_util</th>\n",
       "      <td>9111</td>\n",
       "      <td>4.843108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <td>9027</td>\n",
       "      <td>4.798456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp_length</th>\n",
       "      <td>7877</td>\n",
       "      <td>4.187154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bc_limit</th>\n",
       "      <td>7495</td>\n",
       "      <td>3.984096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <td>7495</td>\n",
       "      <td>3.984096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_util</th>\n",
       "      <td>125</td>\n",
       "      <td>0.066446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Missing_Count  Missing_Percentage\n",
       "desc                          106662           56.698011\n",
       "mths_since_recent_inq          27860           14.809460\n",
       "tot_cur_bal                    27741           14.746203\n",
       "bc_util                         9111            4.843108\n",
       "percent_bc_gt_75                9027            4.798456\n",
       "emp_length                      7877            4.187154\n",
       "total_bc_limit                  7495            3.984096\n",
       "tot_hi_cred_lim                 7495            3.984096\n",
       "revol_util                       125            0.066446"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def missing_percentage(df):\n",
    "    \"\"\"\n",
    "    Print percentage of missing values for all variables in a DataFrame.\n",
    "    \"\"\"\n",
    "    missing = df.isnull().sum()\n",
    "    perc_missing = (missing / len(df)) * 100\n",
    "    result = pd.DataFrame({\n",
    "        'Missing_Count': missing,\n",
    "        'Missing_Percentage': perc_missing\n",
    "    })\n",
    "    result = result[result['Missing_Count'] > 0].sort_values(by='Missing_Percentage', ascending=False)\n",
    "    return result\n",
    "\n",
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "aa = missing_percentage(train_df)\n",
    "print(train_df.shape)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d7c7a76-c808-4b13-ac9f-b2b188dead22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188123, 20)\n",
      "(290628, 20)\n",
      "(188123, 27)\n",
      "(290628, 27)\n"
     ]
    }
   ],
   "source": [
    "def impute_mixed_data_with_train_indicator(df, train_indicator='train_indicator', exclude_cols=['desc', 'bad_flag'], add_missing_ind=True):\n",
    "    \"\"\"\n",
    "    Impute missing values for a combined train+test dataset using train_indicator.\n",
    "    Fits imputers on train data and applies to full dataset.\n",
    "    Handles numeric (Iterative Imputer) and categorical (mode) columns separately.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Split train/test\n",
    "    train_data = df_copy[df_copy[train_indicator] == 1]\n",
    "    \n",
    "    # Numeric columns (excluding target and text columns)\n",
    "    numeric_cols = df_copy.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    num_impute_cols = [c for c in numeric_cols if c not in exclude_cols + [train_indicator]]\n",
    "    \n",
    "    # Categorical columns (object, category)\n",
    "    cat_cols = df_copy.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    cat_impute_cols = [c for c in cat_cols if c not in exclude_cols + [train_indicator]]\n",
    "    \n",
    "    # Add missing indicators for numeric columns\n",
    "    if add_missing_ind:\n",
    "        for col in num_impute_cols:\n",
    "            if df_copy[col].isnull().any():\n",
    "                df_copy[f'{col}_missing_ind'] = df_copy[col].isnull().astype(int)\n",
    "    \n",
    "    # ✅ Numeric: Fit Iterative Imputer on train, transform all\n",
    "    if len(num_impute_cols) > 0:\n",
    "        num_imputer = IterativeImputer(random_state=42)\n",
    "        num_imputer.fit(train_data[num_impute_cols])\n",
    "        df_copy[num_impute_cols] = num_imputer.transform(df_copy[num_impute_cols])\n",
    "    \n",
    "    # ✅ Categorical: Fit SimpleImputer (mode) on train, transform all\n",
    "    if len(cat_impute_cols) > 0:\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        cat_imputer.fit(train_data[cat_impute_cols])\n",
    "        df_copy[cat_impute_cols] = cat_imputer.transform(df_copy[cat_impute_cols])\n",
    "    \n",
    "    return df_copy, num_imputer, cat_imputer\n",
    "\n",
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "print(combined_df.shape)\n",
    "combined_df, _, _ = impute_mixed_data_with_train_indicator(df=combined_df, train_indicator='train_indicator', exclude_cols=['desc', 'bad_flag', 'train_indicator'], add_missing_ind=True)\n",
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00df1553-eca8-48f3-bcb5-1af39e51618a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Missing_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>desc</th>\n",
       "      <td>193973</td>\n",
       "      <td>66.742709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad_flag</th>\n",
       "      <td>102505</td>\n",
       "      <td>35.270174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Missing_Count  Missing_Percentage\n",
       "desc             193973           66.742709\n",
       "bad_flag         102505           35.270174"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae663c-7991-4c54-9306-6ea970254ef3",
   "metadata": {},
   "source": [
    "#### Step 1.2.9. For float independent variables, add log, ^1/2, ^1/3, ^1/4, ^1/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17e022a2-eaab-4e6c-9f29-fcec3d9be90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### idea is to make the numbers smaller to make the data more stable and not affected too much by outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b264089-3fe7-497c-b483-1b5837bef2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188123, 27)\n",
      "(290628, 27)\n",
      "Shape before: (290628, 27)\n",
      "Column 'percent_bc_gt_75': 0.08% of values are negative. Using only 1/3 and 1/5 transforms.\n",
      "Column 'mths_since_recent_inq': 0.18% of values are negative. Using only 1/3 and 1/5 transforms.\n",
      "Column 'tot_cur_bal': 0.03% of values are negative. Using only 1/3 and 1/5 transforms.\n",
      "Shape after: (290628, 118)\n",
      "(188123, 118)\n",
      "(290628, 118)\n"
     ]
    }
   ],
   "source": [
    "def safe_cuberoot(series):\n",
    "    \"\"\"Compute cube root for a pandas Series, handling negatives correctly.\"\"\"\n",
    "    return series.apply(lambda x: -1 * np.power(-x, 1.0/3.0) if x < 0 else np.power(x, 1.0/3.0))\n",
    "\n",
    "def safe_5rt(series):\n",
    "    \"\"\"Compute cube root for a pandas Series, handling negatives correctly.\"\"\"\n",
    "    return series.apply(lambda x: -1 * np.power(-x, 1.0/5.0) if x < 0 else np.power(x, 1.0/5.0))\n",
    "\n",
    "def create_float_transformations(df, excl_vars=None):\n",
    "    \"\"\"\n",
    "    Create transformation columns for float columns based on value ranges:\n",
    "    - If all > 0: log(x), sqrt(x), x^(1/3), x^(1/4), x^(1/5)\n",
    "    - If all >= 0: log(x+1), sqrt(x), x^(1/3), x^(1/4), x^(1/5)\n",
    "    - If any < 0: only x^(1/3), x^(1/5) and print % of negatives\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        Input dataframe.\n",
    "    excl_vars : list or None\n",
    "        Columns to exclude (e.g., target variable).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    df_copy : pandas DataFrame\n",
    "        Dataframe with added transformation columns.\n",
    "    \"\"\"\n",
    "    print(\"Shape before:\", df.shape)\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Identify numeric columns\n",
    "    float_cols = df_copy.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if excl_vars:\n",
    "        float_cols = [c for c in float_cols if c not in excl_vars]\n",
    "\n",
    "    # ✅ Ensure no missing values in selected numeric columns\n",
    "    assert df_copy[float_cols].isnull().sum().sum() == 0, \"NaN values detected in numeric columns. Please impute first.\"\n",
    "\n",
    "    for col in float_cols:\n",
    "        col_data = df_copy[col]\n",
    "        min_val = col_data.min()\n",
    "\n",
    "        if min_val > 0:\n",
    "            # All values > 0: safe for log(x)\n",
    "            df_copy[f'{col}_log'] = np.log(df_copy[col])\n",
    "            df_copy[f'{col}_sqrt'] = np.power(df_copy[col], 1.0/2.0)\n",
    "            df_copy[f'{col}_cbrt'] = np.power(df_copy[col], 1.0/3.0)\n",
    "            df_copy[f'{col}_4rt'] = np.power(df_copy[col], 1.0/4.0)\n",
    "            df_copy[f'{col}_5rt'] = np.power(df_copy[col], 1.0/5.0)\n",
    "\n",
    "        elif min_val >= 0:\n",
    "            # All values >= 0: use log(x+1)\n",
    "            df_copy[f'{col}_log'] = np.log(df_copy[col] + 1)\n",
    "            df_copy[f'{col}_sqrt'] = np.power(df_copy[col], 1.0/2.0)\n",
    "            df_copy[f'{col}_cbrt'] = np.power(df_copy[col], 1.0/3.0)\n",
    "            df_copy[f'{col}_4rt'] = np.power(df_copy[col], 1.0/4.0)\n",
    "            df_copy[f'{col}_5rt'] = np.power(df_copy[col], 1.0/5.0)\n",
    "\n",
    "        else:\n",
    "            # Some values < 0: only 1/3 and 1/5 power transforms\n",
    "            neg_count = (df_copy[col] < 0).sum()\n",
    "            total_values = col_data.shape[0]\n",
    "            perc_negative = (neg_count / total_values) * 100\n",
    "            print(f\"Column '{col}': {perc_negative:.2f}% of values are negative. Using only 1/3 and 1/5 transforms.\")\n",
    "            df_copy[f'{col}_cbrt'] = safe_cuberoot(df_copy[col])\n",
    "            df_copy[f'{col}_5rt'] = safe_5rt(df_copy[col])\n",
    "\n",
    "    print(\"Shape after:\", df_copy.shape)\n",
    "    return df_copy\n",
    "\n",
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "print(combined_df.shape)\n",
    "combined_df = create_float_transformations(df=combined_df, excl_vars=[y_col, ind_col, 'desc'])\n",
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b2840b1-d4b9-452e-829f-b37e69b548e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Missing_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>desc</th>\n",
       "      <td>193973</td>\n",
       "      <td>66.742709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad_flag</th>\n",
       "      <td>102505</td>\n",
       "      <td>35.270174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Missing_Count  Missing_Percentage\n",
       "desc             193973           66.742709\n",
       "bad_flag         102505           35.270174"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b834b77-4cfa-421f-b215-4dfb0f19ddf2",
   "metadata": {},
   "source": [
    "#### Step 1.2.10. handling outliers for numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c193c893-1ca5-4ef2-9e9e-05c3e5effb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## idea is that for each numerical independent variable, if it is approximately normal, then truncate using 3 stddev zscore,\n",
    "## o.w., truncate use 1.5 IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b9d3fd6-6028-4ace-9bc8-3e5951eaedf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188123, 118)\n",
      "(290628, 118)\n",
      "(188123, 308)\n",
      "(290628, 308)\n"
     ]
    }
   ],
   "source": [
    "def detect_and_truncate_outliers_train_test(df, train_indicator='train_indicator', y_var='bad_flag', z_thresh=3.0):\n",
    "    \"\"\"\n",
    "    Detect outliers based on training data and apply to full dataset.\n",
    "    Uses Shapiro test: if normal -> z-score; else -> IQR.\n",
    "    Assumes all NaNs have been removed beforehand.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    train_data = df_copy[df_copy[train_indicator] == 1]\n",
    "    \n",
    "    # ✅ Ensure no missing values before proceeding\n",
    "    numeric_cols = [c for c in df_copy.select_dtypes(include=[np.number]).columns if c not in [y_var, train_indicator, 'desc']]\n",
    "    assert df_copy[numeric_cols].isnull().sum().sum() == 0, \"NaN values detected in numeric columns. Please impute first.\"\n",
    "    \n",
    "    summary = []\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        data = train_data[col]\n",
    "        \n",
    "        # Shapiro-Wilk test for normality (skip if too few samples)\n",
    "        stat, p_value = shapiro(data) if len(data) > 3 else (None, 0)\n",
    "        \n",
    "        if p_value and p_value > 0.05:\n",
    "            # Normal: use z-score\n",
    "            method = \"z-score\"\n",
    "            mean_val = data.mean()\n",
    "            std_val = data.std()\n",
    "            lower_bound = mean_val - z_thresh * std_val\n",
    "            upper_bound = mean_val + z_thresh * std_val\n",
    "        else:\n",
    "            # Not normal: use IQR\n",
    "            method = \"IQR\"\n",
    "            Q1 = data.quantile(0.25)\n",
    "            Q3 = data.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Apply to all data\n",
    "        outlier_mask = (df_copy[col] < lower_bound) | (df_copy[col] > upper_bound)\n",
    "        n_outliers = outlier_mask.sum()\n",
    "        \n",
    "        if n_outliers > 0:\n",
    "            cleaned_col = f\"{col}_cleaned\"\n",
    "            indicator_col = f\"{col}_outlier\"\n",
    "            df_copy[cleaned_col] = df_copy[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "            df_copy[indicator_col] = outlier_mask.astype(int)\n",
    "        \n",
    "        summary.append({\n",
    "            \"Column\": col,\n",
    "            \"Method\": method,\n",
    "            \"Lower_Bound\": lower_bound,\n",
    "            \"Upper_Bound\": upper_bound,\n",
    "            \"Num_Outliers_Total\": int(n_outliers),\n",
    "            \"Num_Outliers_Train\": int(((train_data[col] < lower_bound) | (train_data[col] > upper_bound)).sum())\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    return df_copy, summary_df\n",
    "\n",
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "print(combined_df.shape)\n",
    "combined_df, summary_df = detect_and_truncate_outliers_train_test(df=combined_df, train_indicator='train_indicator', y_var='bad_flag', z_thresh=3.0)\n",
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8174cfa1-206c-4603-acef-39dc67bf8b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Method</th>\n",
       "      <th>Lower_Bound</th>\n",
       "      <th>Upper_Bound</th>\n",
       "      <th>Num_Outliers_Total</th>\n",
       "      <th>Num_Outliers_Train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loan_amnt</td>\n",
       "      <td>IQR</td>\n",
       "      <td>-10000.00000</td>\n",
       "      <td>38000.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>int_rate</td>\n",
       "      <td>IQR</td>\n",
       "      <td>0.01945</td>\n",
       "      <td>0.26465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>IQR</td>\n",
       "      <td>-18000.00000</td>\n",
       "      <td>150000.00000</td>\n",
       "      <td>12520</td>\n",
       "      <td>7501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>percent_bc_gt_75</td>\n",
       "      <td>IQR</td>\n",
       "      <td>-57.50000</td>\n",
       "      <td>162.50000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bc_util</td>\n",
       "      <td>IQR</td>\n",
       "      <td>-9.30000</td>\n",
       "      <td>147.50000</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Column Method  Lower_Bound   Upper_Bound  Num_Outliers_Total  \\\n",
       "0         loan_amnt    IQR -10000.00000   38000.00000                   0   \n",
       "1          int_rate    IQR      0.01945       0.26465                   0   \n",
       "2        annual_inc    IQR -18000.00000  150000.00000               12520   \n",
       "3  percent_bc_gt_75    IQR    -57.50000     162.50000                   1   \n",
       "4           bc_util    IQR     -9.30000     147.50000                  14   \n",
       "\n",
       "   Num_Outliers_Train  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                7501  \n",
       "3                   0  \n",
       "4                   6  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be4b8ae-8ce8-47fb-9870-870001d5decf",
   "metadata": {},
   "source": [
    "#### Step 1.2.10. handling outliers for category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8d7b081-7eb7-4705-be46-f11733de180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## note that home_ownership has only a few observations equal to OTHER or NONE, which are noise, impute them with most frequently \n",
    "## observed value, i.e., MORTGAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f305ab6b-b97f-464a-b342-9e5dfe28a5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home_ownership\n",
      "MORTGAGE    96979\n",
      "RENT        75609\n",
      "OWN         15447\n",
      "OTHER          46\n",
      "NONE           42\n",
      "Name: count, dtype: int64\n",
      "home_ownership\n",
      "MORTGAGE    150243\n",
      "RENT        115139\n",
      "OWN          25158\n",
      "OTHER           46\n",
      "NONE            42\n",
      "Name: count, dtype: int64\n",
      "home_ownership\n",
      "MORTGAGE    97067\n",
      "RENT        75609\n",
      "OWN         15447\n",
      "Name: count, dtype: int64\n",
      "home_ownership\n",
      "MORTGAGE    150331\n",
      "RENT        115139\n",
      "OWN          25158\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(combined_df.loc[combined_df['train_indicator'] == 1, 'home_ownership'].value_counts())\n",
    "print(combined_df['home_ownership'].value_counts())\n",
    "combined_df.loc[combined_df['home_ownership'].isin(['OTHER', 'NONE']), 'home_ownership'] = 'MORTGAGE'\n",
    "print(combined_df.loc[combined_df['train_indicator'] == 1, 'home_ownership'].value_counts())\n",
    "print(combined_df['home_ownership'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c304d-8fd7-40d3-a085-7e03d6329324",
   "metadata": {},
   "source": [
    "#### Step 1.2.11. Extract information from column desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8a3a268-a37c-4a6b-9230-08cf17a89ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## idea is that for a row that contains valid desc, get the length of the desc, then create 1000 dummy columns to count \n",
    "## how many times those keywords shows up in current desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f508ed25-7d6f-4445-b20d-0373cf27c65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188123, 308)\n",
      "(290628, 308)\n",
      "(188123, 1309)\n",
      "(290628, 1309)\n"
     ]
    }
   ],
   "source": [
    "def create_text_features(df, text_col='desc', top_n=1000, train_indicator='train_indicator'):\n",
    "    \"\"\"\n",
    "    Create text features:\n",
    "    - desc_length: number of words per row.\n",
    "    - Top N most common words based on TRAINING data only.\n",
    "    - Word count dummy variables applied to full dataset.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # ✅ Safe length calculation with null handling\n",
    "    df_copy['desc_length'] = df_copy[text_col].astype(str).apply(\n",
    "        lambda x: len(re.findall(r'\\b\\w+\\b', x)) if x.lower() != 'nan' else 0\n",
    "    ).astype(int)\n",
    "\n",
    "    # ✅ Build vocabulary using TRAINING data only (non-null rows)\n",
    "    train_text = \" \".join(\n",
    "        df_copy.loc[df_copy[train_indicator] == 1, text_col].dropna().astype(str)\n",
    "    )\n",
    "    words = re.findall(r'\\b\\w+\\b', train_text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [w for w in words if w not in stop_words]\n",
    "    word_counts = Counter(filtered_words)\n",
    "    most_common_words = [w for w, _ in word_counts.most_common(top_n)]\n",
    "\n",
    "    # ✅ Apply word counts to full dataset (train + test)\n",
    "    for word in most_common_words:\n",
    "        pattern = re.compile(rf'\\b{re.escape(word)}\\b', re.IGNORECASE)\n",
    "        df_copy[f'word_{word}'] = df_copy[text_col].astype(str).apply(\n",
    "            lambda x: len(pattern.findall(x)) if x.lower() != 'nan' else 0\n",
    "        )\n",
    "\n",
    "    return df_copy, most_common_words\n",
    "\n",
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "print(combined_df.shape)\n",
    "combined_df, _ = create_text_features(df=combined_df, text_col='desc', top_n=1000, train_indicator='train_indicator')\n",
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2716740-3895-4bfd-b0bb-5abaa5ae5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove desc\n",
    "del combined_df['desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61768bf9-4061-4502-a4aa-752d003df8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Missing_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bad_flag</th>\n",
       "      <td>102505</td>\n",
       "      <td>35.270174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Missing_Count  Missing_Percentage\n",
       "bad_flag         102505           35.270174"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc21c540-51c7-4fe9-bb08-0996674fa6eb",
   "metadata": {},
   "source": [
    "#### Step 1.2.12. One hot encoding all category variables and then remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9f82364-6c47-47b4-a091-b941aca0aeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188123, 1308)\n",
      "(290628, 1308)\n",
      "['term', 'emp_length', 'home_ownership', 'purpose']\n",
      "(188123, 1333)\n",
      "(290628, 1333)\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode_objects(df, drop_first=False):\n",
    "    \"\"\"\n",
    "    One-hot encode all object columns in a DataFrame and drop the original columns.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        Input dataset.\n",
    "    drop_first : bool, default=False\n",
    "        Whether to drop the first level to avoid dummy variable trap.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    df_encoded : pandas DataFrame\n",
    "        DataFrame with object columns one-hot encoded and original object columns removed.\n",
    "    object_cols : list\n",
    "        List of columns that were encoded.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Identify object columns\n",
    "    object_cols = df_copy.select_dtypes(include=['object']).columns.tolist()\n",
    "    print(object_cols)\n",
    "    \n",
    "    # One-hot encode object columns\n",
    "    if object_cols:\n",
    "        dummies = pd.get_dummies(df_copy[object_cols], prefix=object_cols, drop_first=drop_first)\n",
    "        df_copy = pd.concat([df_copy.drop(columns=object_cols), dummies], axis=1)\n",
    "    \n",
    "    return df_copy, object_cols\n",
    "\n",
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "print(combined_df.shape)\n",
    "combined_df, _ = one_hot_encode_objects(combined_df, drop_first=False)\n",
    "train_df = combined_df.loc[combined_df[ind_col] == 1, :].copy()\n",
    "print(train_df.shape)\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91e3c1bd-abff-4fc0-9aaf-4ab14a416a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Missing_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bad_flag</th>\n",
       "      <td>102505</td>\n",
       "      <td>35.270174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Missing_Count  Missing_Percentage\n",
       "bad_flag         102505           35.270174"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a4bb929-e821-4007-8622-8ce7be052fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>bc_util</th>\n",
       "      <th>dti</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>...</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_house</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_medical</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_renewable_energy</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>purpose_vacation</th>\n",
       "      <th>purpose_wedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7550.0</td>\n",
       "      <td>0.1624</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.720</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27050.0</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.9</td>\n",
       "      <td>22.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.612</td>\n",
       "      <td>35700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>4.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.240</td>\n",
       "      <td>18100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>67.1</td>\n",
       "      <td>18.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.546</td>\n",
       "      <td>42200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>79.6</td>\n",
       "      <td>16.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.688</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  annual_inc  percent_bc_gt_75  bc_util    dti  \\\n",
       "0     7550.0    0.1624     28000.0             100.0     96.0   8.40   \n",
       "1    27050.0    0.1099     55000.0              25.0     53.9  22.87   \n",
       "2    12000.0    0.1099     60000.0               0.0     15.9   4.62   \n",
       "3    28000.0    0.0762    325000.0              16.7     67.1  18.55   \n",
       "4    12000.0    0.1353     40000.0              33.3     79.6  16.94   \n",
       "\n",
       "   inq_last_6mths  mths_since_recent_inq  revol_util  total_bc_limit  ...  \\\n",
       "0             0.0                   17.0       0.720          4000.0  ...   \n",
       "1             0.0                    8.0       0.612         35700.0  ...   \n",
       "2             1.0                    3.0       0.240         18100.0  ...   \n",
       "3             1.0                    3.0       0.546         42200.0  ...   \n",
       "4             0.0                   17.0       0.688          7000.0  ...   \n",
       "\n",
       "   purpose_home_improvement  purpose_house  purpose_major_purchase  \\\n",
       "0                     False          False                   False   \n",
       "1                     False          False                   False   \n",
       "2                     False          False                   False   \n",
       "3                     False          False                   False   \n",
       "4                     False          False                   False   \n",
       "\n",
       "   purpose_medical  purpose_moving  purpose_other  purpose_renewable_energy  \\\n",
       "0            False           False          False                     False   \n",
       "1            False           False          False                     False   \n",
       "2            False           False          False                     False   \n",
       "3            False           False          False                     False   \n",
       "4            False           False          False                     False   \n",
       "\n",
       "   purpose_small_business  purpose_vacation  purpose_wedding  \n",
       "0                   False             False            False  \n",
       "1                   False             False            False  \n",
       "2                   False             False            False  \n",
       "3                   False             False            False  \n",
       "4                   False             False            False  \n",
       "\n",
       "[5 rows x 1333 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1139fa6e-c611-45c5-b281-5bb9994c4af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.to_hdf('C:/Users/xiaow/work/jp_awm/interview/Take Home Project/combined_train_test_cleaned.hdf5', key='data')\n",
    "aa = pd.read_hdf('C:/Users/xiaow/work/jp_awm/interview/Take Home Project/combined_train_test_cleaned.hdf5')\n",
    "aa.equals(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3157095-e7af-4ad1-8df3-019f126e99cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a9a76-65b1-4bfd-a62a-ead947a33ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa40c9-f20b-4333-8b50-788e8f2ee1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e593c9f2-c0fd-4fa2-86ba-a35e195e489b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ede7a-e79e-4dff-8b28-0f92980f2b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76e729-18fe-46ac-9126-62999414089c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b34bb91-6dcd-4828-a48b-4fb378365dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cef45f-ef1d-480a-a245-26ee534830e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960d849e-93aa-4366-9469-05f7ef904e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690df9a8-2bc6-4f5f-96db-9d3a16c6c2df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe8939b-e008-4c88-9f6c-4a46d69527f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
